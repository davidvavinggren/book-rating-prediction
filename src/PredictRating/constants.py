# Tokenizer
MAX_LEN = 512

# Training
DATA_PERCENTAGE = 1
TRAIN_SPLIT = 0.8
TRAIN_BATCH_SIZE = 32
TEST_BATCH_SIZE = 32
EPOCHS = 5
LEARNING_RATE = 5e-05

# Network
DROPOUT_PROB = 0.1