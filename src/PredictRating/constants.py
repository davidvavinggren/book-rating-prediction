# Tokenizer
MAX_LEN = 512

# Training
DATA_PERCENTAGE = 1
TRAIN_SPLIT = 0.8
TRAIN_BATCH_SIZE = 8
TEST_BATCH_SIZE = 4
EPOCHS = 10
LEARNING_RATE = 1e-05

# Network
DROPOUT_PROB = 0.4